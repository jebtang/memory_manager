\section{Related Work}
\label{sec:related}
\paragraph{}
Memory tracing mechanisms such as Valgrind's memcheck \cite{nethercote2007valgrind}, gdb's ptrace \cite{gdb}, SSDAlloc's \cite{SSDAlloc} page protection mechanism rely on system call interfaces for  fine grained memory access. The overheads incurred due the reliance on system calls can downgrade the performance of the application. Kernel crossings result in interrupts to kernel, mode switches and data and instruction cache pollution. {\emph{Indirection}} mechanisms (such as those based on handles) have been previously used in HAC \cite{castro1997hac} and Mac memory management systems. Handle, based approaches trade off backward compatibility and provide finer monitoring of application data. We next describe systems based on memory protection mechanisms.

\paragraph{SSDAlloc's page protection mechanism}
SSDAlloc monitors fine grained access patterns through the use of an Object Per Page model, where each object is placed in its own page of virtual memory. SSDAlloc's DRAM is split into an object cache (which composes most of DRAM), and a Page Buffer that holds the set of materialized pages currently being used by the application (where each object is stored in its own physical page). SSDAlloc protects all virtual memory that it allocates, so any memory access for an unmaterialized page generates a page fault and is sent to SSDAlloc's interrupt handler. The handler would then pull the object from the object cache or the SSD, unprotect it and materialize it in the page buffer, and send it back to the application. This allows SSDAlloc to track memory accesses at an object level granularity as opposed to a page level granularity, since each virtual memory page access can be directly mapped to a single object access. Workloads that touch larger memory segments (such as tree creation, tree traversal) may not be fully resident within the page buffer. This could lead to heavy overheads due to interrupt call, object eviction from page buffer and page materialization.

\paragraph{Chameleon's memory tiering mechanism}
Chameleon improves on SSDAlloc's design by removing the need to split DRAM into a cache and page buffer entirely. Each object is still put into a single virtual page, but the virtual pages are partitioned into a set of object sized chunks, and the object is randomly placed into one of these chunks in the virtual page. Since these chunks can be mapped to a chunks in a physical page, a single physical page can store objects from multiple virtual pages. Chameleon requires memory object alignment at boundary offsets. This could lead to some memory wastage over standard memory allocation schemes. As with SSDAlloc the OPP model increases TLB pressure. Tracer does not make such assumptions for tracking object accesses.

\paragraph{Memory tracing systems}
Our design is inspired from {\emph{memlet}} based systems \cite{}. {\emph{Memlets}} are small pieces of code which are injected into application code. These code sequences execute additional code for every memory access and monitor application access pattern at  a finer granularity. Memlets are generally weaved into into application code through {\emph{binary translation techniques, watchpoints, taint checking and data flow analysis}}.
Binary translation techniques modify code after the the application has been compiled to binary format. Binary translators {\cite{nethercote2007valgrind,bellard2005qemu}}convert programs to intermediate representation and then perform dynamic or static translation to improve the overall performance. Greathouse et al. \cite{greathouse2012case} describe a system for adding unlimited {\emph{watchpoints}} using hardware extensions (bitmap translation look aside buffer and a range cache) which can provide fine grained memory monitoring. Taint checking \cite{newsome2005dynamic, ho2006practical} and data flow analysis systems use additional taints per memory location and registers for registering accesses to them. Tracer "taints" memory structures with metadata (as headers) for monitoring accessing and updating access count information.

\paragraph{}
